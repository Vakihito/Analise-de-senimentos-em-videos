### [Overview](#overview)  | [Steps](#steps) | [Notebooks](#notebooks) | [Results](#results) | [Students](#students) | [References](#references) 

# Face Extraction

This is the final project for the image processing course at the University of São Paulo (USP)

---
## Overview

In this project I did a sistem for sentiment classification in vídeos.

In order to do this I did the following steps:
 1. Image Feature Extraction - since we could not use CNN's we used SIFT descriptors in conjunction with k-means in order to generate the bag-of-visual-words.
 2. Face Extraction model - With the extracted features from the _Image Feature Extraction_ step, we use diferent types of models to create a bouding box around the face.

---
## Steps

### **Image Feature Extraction**

In order to describe an image I use the SIFT descriptor. The SIFT descriptor will describe an image as a list of vectors. Since we need to create words that describe an image, we first use k-means model on the vectors generated by the SIFT descritor, this will cluster the vectors that describes the images to a cluster. Tha being said, the idea is that each cluster will be representing a bag-of-visual-word, and since each image is composed by multiple SIFT vectors, each SIFT vector will be "mapped" to a cluster wich is also visual-word. 

Now that an image is described as multiple visual-words, we just need to create the ocorrences that each visual-word occurs in the image, so I create a histogram of ocorrences of visual-words in a image. 

---
## Notebooks
Please see the following tutorial notebooks for a guide on how to use this project
 - **Image Feature Extraction** : [notebook](https://colab.research.google.com/drive/1J5B1rTAGaAfFelf8P9d4lXzjjH1j_WBr#scrollTo=rLKUJZz0eCGp)


---
## Results

---
## Students
  - Victor Akihito Kamada Tomita - 10692082
---
## References
  - [Wider Dataset](http://shuoyang1213.me/WIDERFACE/)
